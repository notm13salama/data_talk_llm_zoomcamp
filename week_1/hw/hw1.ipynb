{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch({'host': 'localhost', 'port': 9200, 'scheme': 'http'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m.salama\\AppData\\Local\\Temp\\ipykernel_19676\\2000385392.py:18: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.indices.create(index=index_name, body=index_settings)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [dt_faq/I3-z7RU0RFaxiABdDOGnvg] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m index_settings \u001b[39m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msettings\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnumber_of_shards\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     }\n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     16\u001b[0m index_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdt_faq\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m es\u001b[39m.\u001b[39;49mindices\u001b[39m.\u001b[39;49mcreate(index\u001b[39m=\u001b[39;49mindex_name, body\u001b[39m=\u001b[39;49mindex_settings)\n",
      "File \u001b[1;32mc:\\Users\\m.salama\\.conda\\envs\\llm-zc\\lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\m.salama\\.conda\\envs\\llm-zc\\lib\\site-packages\\elasticsearch\\_sync\\client\\indices.py:517\u001b[0m, in \u001b[0;36mIndicesClient.create\u001b[1;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m __body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m     __headers[\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 517\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_request(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m    518\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, __path, params\u001b[39m=\u001b[39;49m__query, headers\u001b[39m=\u001b[39;49m__headers, body\u001b[39m=\u001b[39;49m__body\n\u001b[0;32m    519\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\m.salama\\.conda\\envs\\llm-zc\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:390\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mperform_request\u001b[39m(\n\u001b[0;32m    380\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    381\u001b[0m     method: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[39m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m    391\u001b[0m         method, path, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, body\u001b[39m=\u001b[39;49mbody\n\u001b[0;32m    392\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\m.salama\\.conda\\envs\\llm-zc\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:321\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    319\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m     \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(meta\u001b[39m.\u001b[39mstatus, ApiError)(\n\u001b[0;32m    322\u001b[0m         message\u001b[39m=\u001b[39mmessage, meta\u001b[39m=\u001b[39mmeta, body\u001b[39m=\u001b[39mresp_body\n\u001b[0;32m    323\u001b[0m     )\n\u001b[0;32m    325\u001b[0m \u001b[39m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch:\n\u001b[0;32m    327\u001b[0m     \u001b[39m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [dt_faq/I3-z7RU0RFaxiABdDOGnvg] already exists')"
     ]
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"dt_faq\"\n",
    "\n",
    "es.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [01:03<00:00, 15.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es.index(index='dt_faq', document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def search(q, topk=5, index_name='dt_faq', filters=None):\n",
    "    search_query = {\n",
    "            \"size\": topk,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": q,\n",
    "                            \"fields\": [\"question^4\", \"text\"],\n",
    "                            \"type\": \"best_fields\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": filters\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    res = es.search(index=index_name, body=search_query)\n",
    "\n",
    "    results = []\n",
    "    for hit in res['hits']['hits']:\n",
    "        results.append(hit[\"_source\"])\n",
    "        pprint(hit['_score'])\n",
    "        pprint(hit[\"_source\"])\n",
    "        print('---')\n",
    "        print() \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.38676\n",
      "{'course': 'machine-learning-zoomcamp',\n",
      " 'question': 'How do I debug a docker container?',\n",
      " 'section': '5. Deploying Machine Learning Models',\n",
      " 'text': 'Launch the container image in interactive mode and overriding the '\n",
      "         'entrypoint, so that it starts a bash command.\\n'\n",
      "         'docker run -it --entrypoint bash <image>\\n'\n",
      "         'If the container is already running, execute a command in the '\n",
      "         'specific container:\\n'\n",
      "         'docker ps (find the container-id)\\n'\n",
      "         'docker exec -it <container-id> bash\\n'\n",
      "         '(Marcos MJD)'}\n",
      "---\n",
      "\n",
      "66.688705\n",
      "{'course': 'machine-learning-zoomcamp',\n",
      " 'question': 'How do I copy files from my local machine to docker container?',\n",
      " 'section': '5. Deploying Machine Learning Models',\n",
      " 'text': 'You can copy files from your local machine into a Docker container '\n",
      "         \"using the docker cp command. Here's how to do it:\\n\"\n",
      "         'To copy a file or directory from your local machine into a running '\n",
      "         'Docker container, you can use the `docker cp command`. The basic '\n",
      "         'syntax is as follows:\\n'\n",
      "         'docker cp /path/to/local/file_or_directory '\n",
      "         'container_id:/path/in/container\\n'\n",
      "         'Hrithik Kumar Advani'}\n",
      "---\n",
      "\n",
      "59.812744\n",
      "{'course': 'machine-learning-zoomcamp',\n",
      " 'question': 'How do I copy files from a different folder into docker '\n",
      "             'container’s working directory?',\n",
      " 'section': '5. Deploying Machine Learning Models',\n",
      " 'text': 'You can copy files from your local machine into a Docker container '\n",
      "         \"using the docker cp command. Here's how to do it:\\n\"\n",
      "         'In the Dockerfile, you can provide the folder containing the files '\n",
      "         'that you want to copy over. The basic syntax is as follows:\\n'\n",
      "         'COPY [\"src/predict.py\", \"models/xgb_model.bin\", '\n",
      "         '\"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'}\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m.salama\\AppData\\Local\\Temp\\ipykernel_19676\\1936798363.py:20: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  res = es.search(index=index_name, body=search_query)\n"
     ]
    }
   ],
   "source": [
    "q =  \"How do execute a command on a Kubernetes pod?\"\n",
    "q =\"How do copy a file to a Docker container?\"\n",
    "filters = {\n",
    "    \"term\": {\n",
    "        \"course\": \"machine-learning-zoomcamp\"\n",
    "    }\n",
    "}\n",
    "contx = search(q, filters=filters, topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "query = \"\"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "QUESTION: How do copy a file to a Docker container?\n",
      "CONTEXT:\n",
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "Q: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n"
     ]
    }
   ],
   "source": [
    "all_contx = []\n",
    "for c in contx:\n",
    "    all_contx.append(context_template.format(question=c['question'], text=c['text']))\n",
    "\n",
    "query = query.format(question=q, context='\\n\\n'.join(all_contx)).strip()\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1447"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    }
   ],
   "source": [
    "print(len(encoding.encode(query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
